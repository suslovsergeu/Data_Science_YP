{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Общее-впечатление\" data-toc-modified-id=\"Общее-впечатление-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление</font></a></span></li><li><span><a href=\"#Общее-впечатление-(ревью-2)\" data-toc-modified-id=\"Общее-впечатление-(ревью-2)-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление (ревью 2)</font></a></span></li></ul></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Первичный-анализ\" data-toc-modified-id=\"Первичный-анализ-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Первичный анализ</a></span></li><li><span><a href=\"#Приведение-данных\" data-toc-modified-id=\"Приведение-данных-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Приведение данных</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Подбор-модели\" data-toc-modified-id=\"Подбор-модели-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Подбор модели</a></span></li><li><span><a href=\"#Тест-модели\" data-toc-modified-id=\"Тест-модели-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Тест модели</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Первичный анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дубликатов 0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "df.info()\n",
    "display(df.head())\n",
    "print('Дубликатов', df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет содержит 159,571 наблюдение. Пропусков и дубликатов нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Приведение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#text lemmatization\n",
    "m = WordNetLemmatizer()\n",
    "def lemmatize(text):\n",
    "    lem = \"\".join(m.lemmatize(text)).lower()\n",
    "    return lem\n",
    "\n",
    "def clear_text(text):\n",
    "    t = re.sub(r'[^a-zA-Z ]', ' ', text)\n",
    "    t = t.split()\n",
    "    return \" \".join(t)\n",
    "\n",
    "df['lem_text'] = df['text'].apply(clear_text).apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples split\n",
    "df_train, df_test = train_test_split(df, test_size=0.25, random_state=12345)\n",
    "\n",
    "target_train = df_train['toxic']\n",
    "target_test = df_test['toxic']\n",
    "\n",
    "corpus_train = df_train['lem_text'].values.astype('U')\n",
    "corpus_test = df_test['lem_text'].values.astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorization\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "tf_idf = count_tf_idf.fit(corpus_train)\n",
    "features_train = tf_idf.transform(corpus_train)\n",
    "features_test = tf_idf.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross val score: 0.75\n",
      "CPU times: user 1min 7s, sys: 13.7 s, total: 1min 21s\n",
      "Wall time: 10.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#LogisticRegression\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "cvs = cross_val_score(model, features_train, target_train, cv=5, scoring='f1').mean()\n",
    "print(f'cross val score: {cvs:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best depth - 4, cross val score: 0.42\n",
      "CPU times: user 2min 3s, sys: 415 ms, total: 2min 4s\n",
      "Wall time: 2min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#DecisionTreeClassifier\n",
    "cvs_max = 0\n",
    "depth_best = 1\n",
    "for i in range(1, 5):\n",
    "    model = DecisionTreeClassifier(max_depth=i, random_state=12345, class_weight='balanced')\n",
    "    cvs = cross_val_score(model, features_train, target_train, cv=5, scoring='f1').mean()\n",
    "    if cvs > cvs_max:\n",
    "        cvs_max = cvs\n",
    "        depth_best = i\n",
    "    \n",
    "print(f'best depth - {depth_best}, cross val score: {cvs_max:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best depth - 4, best estimators - 4, cross val score: 0.23\n",
      "CPU times: user 12.2 s, sys: 23.7 ms, total: 12.2 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#RandomForestClassifier\n",
    "cvs_max = 0\n",
    "depth_best = 1\n",
    "est_best = 1\n",
    "for i in range(1, 5):\n",
    "    for j in range(1, 5):\n",
    "        model = RandomForestClassifier(max_depth=i, n_estimators=j, random_state=12345, class_weight='balanced')\n",
    "        cvs = cross_val_score(model, features_train, target_train, cv=5, scoring='f1').mean()\n",
    "        if cvs > cvs_max:\n",
    "            cvs_max = cvs\n",
    "            depth_best = i\n",
    "            est_best = j\n",
    "    \n",
    "print(f'best depth - {depth_best}, best estimators - {est_best}, cross val score: {cvs_max:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тест модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучший результат показала модель логистической регрессии. Оценим ее на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score: 0.76\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight='balanced')\n",
    "model.fit(features_train,target_train)\n",
    "predicted = model.predict(features_test)\n",
    "f1 = f1_score(target_test, predicted)\n",
    "print(f'f1-score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель логистической регрессии для оценки эмоционального окраса выглядит наиболее оптимальной, так как предоставляет наивысший результат cross_val_score, сопровождаемый гораздо более высокой скоростью работы. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
